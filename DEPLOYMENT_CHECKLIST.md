# Deployment Checklist

Use this checklist to verify everything is properly set up and ready for deployment or demonstration.

## âœ… Pre-Deployment Checklist

### Infrastructure Setup
- [x] Docker and Docker Compose installed
- [x] Python 3.10+ installed
- [x] PostgreSQL container running
- [x] Redis container running
- [x] Network connectivity verified

### Database Setup
- [x] PostgreSQL database `datawarehouse` created
- [x] All schemas created (bronze, silver, gold, ml_optimization)
- [x] Extensions installed (pg_stat_statements)
- [x] All tables created and indexed
- [x] Connection credentials configured

### Data Population
- [x] Bronze layer data loaded (7.3M+ records)
- [x] Silver layer data transformed (460K+ records)
- [x] Gold layer data aggregated (15K+ records)
- [x] Data integrity verified

### ETL Pipeline
- [x] ETL scripts functional
- [x] Bronze â†’ Silver transformation working
- [x] Silver â†’ Gold aggregation working
- [x] Batch processing verified

### ML Optimization
- [x] Query log collection working
- [x] Query logs collected (893+ records)
- [x] ML models trained (2 models)
- [x] Recommendations generated (4 recommendations)
- [x] Admin approval system functional
- [x] Performance tests passing

### Testing
- [x] Performance tests executed
- [x] Test results stored
- [x] Baseline metrics established
- [x] Optimization effectiveness measured

### Documentation
- [x] README.md complete
- [x] Quick Start Guide complete
- [x] API documentation available
- [x] Configuration guides available

## ðŸ” Verification Steps

### 1. Service Status

```bash
# Check Docker services
docker-compose ps

# Expected output: postgres and redis should be "Up" and "healthy"
```

### 2. Database Connectivity

```bash
# Test PostgreSQL connection
docker-compose exec postgres psql -U postgres -d datawarehouse -c "SELECT 1;"

# Expected: Should return "1"
```

### 3. Schema Verification

```sql
-- Check all schemas exist
SELECT schema_name FROM information_schema.schemata 
WHERE schema_name IN ('bronze', 'silver', 'gold', 'ml_optimization');

-- Expected: 4 schemas should be listed
```

### 4. Data Verification

```sql
-- Bronze layer
SELECT 
    (SELECT COUNT(*) FROM bronze.raw_customers) as customers,
    (SELECT COUNT(*) FROM bronze.raw_products) as products,
    (SELECT COUNT(*) FROM bronze.raw_orders) as orders;

-- Expected: customers=10000, products=5000, orders=112501

-- Silver layer
SELECT 
    (SELECT COUNT(*) FROM silver.customers) as customers,
    (SELECT COUNT(*) FROM silver.products) as products,
    (SELECT COUNT(*) FROM silver.orders) as orders;

-- Expected: customers=10000, products=5000, orders=112501

-- Gold layer
SELECT 
    (SELECT COUNT(*) FROM gold.daily_sales_summary) as sales_summary,
    (SELECT COUNT(*) FROM gold.customer_360) as customer_360,
    (SELECT COUNT(*) FROM gold.product_performance) as product_perf;

-- Expected: sales_summary=30, customer_360=10000, product_perf=5000
```

### 5. ML Optimization Verification

```sql
-- Query logs
SELECT COUNT(*) FROM ml_optimization.query_logs;
-- Expected: 893+

-- Recommendations
SELECT COUNT(*) FROM ml_optimization.index_recommendations;
-- Expected: 4

-- Performance tests
SELECT COUNT(*) FROM ml_optimization.performance_test_results;
-- Expected: 5+
```

### 6. ML Models Verification

```bash
# Check saved models
ls ml-optimization/saved_models/

# Expected files:
# - workload_clustering_simple.pkl
# - query_time_predictor_simple.pkl
```

## ðŸš€ Deployment Steps

### Development Environment

1. **Start Core Services**
   ```bash
   docker-compose up -d postgres redis
   ```

2. **Verify Services**
   ```bash
   docker-compose ps
   docker-compose logs postgres
   ```

3. **Run ETL (if needed)**
   ```bash
   python etl/scripts/run_etl.py
   ```

4. **Collect Query Logs**
   ```bash
   $env:PYTHONPATH="$PWD\ml-optimization;$env:PYTHONPATH"
   python scripts/ml-optimization/run_query_collection.py
   ```

5. **Generate Recommendations**
   ```bash
   python scripts/ml-optimization/generate_recommendations.py
   ```

### Production Environment

1. **Review Environment Variables**
   - Check `ENV_TEMPLATE.md`
   - Set secure passwords
   - Configure production URLs

2. **Database Backup**
   ```bash
   docker-compose exec postgres pg_dump -U postgres datawarehouse > backup.sql
   ```

3. **Security Hardening**
   - Change default passwords
   - Configure firewall rules
   - Enable SSL/TLS for database
   - Restrict network access

4. **Monitoring Setup**
   - Configure Prometheus
   - Set up Grafana dashboards
   - Enable alerting

5. **Backup Strategy**
   - Schedule regular backups
   - Test restore procedures
   - Document recovery process

## ðŸ“Š Health Checks

### Database Health

```sql
-- Check table sizes
SELECT 
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
FROM pg_tables
WHERE schemaname IN ('bronze', 'silver', 'gold')
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
LIMIT 10;

-- Check index usage
SELECT 
    schemaname,
    tablename,
    indexname,
    idx_scan as index_scans
FROM pg_stat_user_indexes
WHERE schemaname IN ('bronze', 'silver', 'gold')
ORDER BY idx_scan DESC
LIMIT 20;
```

### Query Performance

```sql
-- Top slow queries
SELECT 
    query,
    calls,
    mean_exec_time,
    total_exec_time
FROM pg_stat_statements
ORDER BY mean_exec_time DESC
LIMIT 10;
```

### ML Optimization Status

```sql
-- Recent recommendations
SELECT 
    recommendation_id,
    table_name,
    column_name,
    priority,
    status,
    created_at
FROM ml_optimization.index_recommendations
ORDER BY created_at DESC;

-- Approval status
SELECT 
    r.recommendation_id,
    r.table_name,
    r.column_name,
    a.status,
    a.approved_by,
    a.approved_at
FROM ml_optimization.index_recommendations r
LEFT JOIN ml_optimization.recommendation_approvals a 
    ON r.recommendation_id = a.recommendation_id
ORDER BY a.approved_at DESC;
```

## ðŸ”§ Troubleshooting

### Common Issues

1. **Database Connection Failed**
   - Check if PostgreSQL is running: `docker-compose ps`
   - Verify credentials in environment variables
   - Check network connectivity

2. **Import Errors (Python)**
   - Set PYTHONPATH: `$env:PYTHONPATH="$PWD\ml-optimization;$env:PYTHONPATH"`
   - Install dependencies: `pip install -r requirements.txt`

3. **Query Logs Empty**
   - Ensure `pg_stat_statements` is enabled
   - Run queries before collecting logs
   - Check PostgreSQL configuration

4. **ML Model Training Fails**
   - Verify query logs exist: `SELECT COUNT(*) FROM ml_optimization.query_logs`
   - Check minimum data requirements (10+ records)
   - Install scikit-learn: `pip install scikit-learn`

5. **Performance Tests Fail**
   - Verify data exists in tables
   - Check query syntax
   - Ensure sufficient data for testing

## ðŸ“ˆ Performance Benchmarks

### Expected Performance

Based on current test results:

| Test | Expected Time | Current Average |
|------|---------------|-----------------|
| orders_by_date | < 2ms | 1.39ms âœ… |
| customer_lookup | < 1ms | 0.69ms âœ… |
| products_by_category | < 2ms | 1.08ms âœ… |
| orders_join_customers | < 3ms | 1.68ms âœ… |
| sales_summary | < 10ms | 8.69ms âœ… |

## âœ… Sign-Off

- [ ] All services running
- [ ] All data loaded
- [ ] ETL pipeline tested
- [ ] ML models trained
- [ ] Recommendations generated
- [ ] Performance tests passing
- [ ] Documentation reviewed
- [ ] Security reviewed
- [ ] Backup strategy in place

## ðŸ“ Deployment Notes

Date: _______________
Deployed by: _______________
Environment: _______________
Version: 1.0.0

### Changes Made:
- [ ] Initial deployment
- [ ] Configuration changes
- [ ] Data updates
- [ ] Model retraining
- [ ] Optimization applied

### Issues Encountered:
- None / Document issues here

### Next Steps:
- [ ] Monitor performance
- [ ] Review recommendations
- [ ] Schedule model retraining
- [ ] Update documentation

---

**Status**: Ready for Deployment âœ…
**Last Verified**: December 25, 2025

